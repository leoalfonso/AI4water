{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c504104-b540-40df-a8ee-91dfe91b6fcd",
   "metadata": {},
   "source": [
    "<div>\n",
    "<table style=\"width: 100%\">\n",
    "    <td>\n",
    "\t<tr>\n",
    "\t\t<td>\n",
    "\t\t<table style=\"width: 100%\">\n",
    "\t\t\t<tr>\n",
    "                <td ><center><font size=\"30\">WSD 2024-2025</font><center>\n",
    "                    <center><font size=\"30\">AI 4 Water Systems</font><center></td>\n",
    "\t\t\t</tr>\n",
    "\t\t\t<tr>\n",
    "                <td><center><font size=\"5\">Jupyter Notebook 1</font><center></td>\n",
    "\t\t\t</tr>\n",
    "\t\t\t<tr>\n",
    "                <td><center><font size=\"10\">Data Analysis</font><center></td>\n",
    "\t\t\t</tr>\n",
    "            <tr>\n",
    "                <td><center><font size=\"5\">Claudia Bertini, Lecturer in Hydroinformatics</font><center></td>\n",
    "\t\t\t</tr> \n",
    "\t\t</table>\n",
    "\t\t<td> <img src='ihe-logo-square.png'></img></td>\n",
    "\t</tr>\n",
    "</table>\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580a4ca-c897-41fe-bae0-1b0464b98785",
   "metadata": {},
   "source": [
    "# Recap and scope of this notebook\n",
    "We aim at developing a data driven model that is predicting discharge in the next hour (Qt+1) using past rainfall and discharge hourly data. Throughout these 3 notebooks, we will learn how to pre-define the input features of the data driven model (Notebook 1), how to build a linear regression model and a M5 Tree model (Notebook 2), how to build an Artificial Neural Network (ANN, Notebook 3).\n",
    "\n",
    "In <b>Notebook 1</b> we will learn how to load and visualize the data and how to use (linear) correlation and autocorrelation to identify the potential relevant input features for the data driven model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966a886-1946-4d19-b965-216c5b0f2ed6",
   "metadata": {},
   "source": [
    "# 1. Installing and importing the libraries needed\n",
    "Before importing the libraries below, you might need to install them. You can use the following commands (the code to be run is in the following cells):\n",
    "pip install matplotlib\n",
    "pip install pandas\n",
    "pip install openpyxl\n",
    "\n",
    "The library os should be automatically installed. If it is not the case, you can add a cell and type \"pip install os\", then run it.\n",
    "If you are running this notebook in Google Colab, you do not need to install the libraries needed for this tutorial as they are already included in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667e1a7-7ba2-41df-9288-b576c578bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237010c9-9e87-47d3-a713-857de381c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20016dea-e1a4-4b4e-b629-8e2135b14e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50062f60-7ed4-4ce6-8750-17dde578ade6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e3bfd-668e-4456-9076-2ab455159145",
   "metadata": {},
   "source": [
    "# 2. Load the data\n",
    "To load the data correctly, first make sure that the file \"Sieve-orig.xlsx\" is saved in the same folder of this notebook. If it's not the case, please move the file to the folder of this notebook.\n",
    "The file contains the hourly records of discharge (Qt) and effective precipitation (REt), from 1 Dec 1969 to 28 Feb 1970. There is also one column providing information about date and time.\n",
    "In the first lines of the next cell, you will find information to be able to open this notebook in Google Colab, in case you prefer it. In case you are running the notebook through colab, you first need to upload the excel file \"Sieve-orig.xlsx\" in your Drive folder (My Drive), as it is where the code will go and look for the data before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7c9bc-853f-4a30-9dbf-eb6a41153fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define file path and check environment\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_path = '/content/drive/My Drive/'\n",
    "else:\n",
    "    base_path = os.getcwd()  # Use current directory in Jupyter Notebook = directory where the notebook is locally saved in your computer\n",
    "\n",
    "# Ensure file exists before reading\n",
    "file_name = 'Sieve-orig.xlsx'\n",
    "file_path = os.path.join(base_path, file_name)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "# First load the file with the data from Sieve\n",
    "df = pd.read_excel(file_path)\n",
    "# you can visualize some of the data by printing the heading\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422586e2-537c-4c53-97e9-2484d6113528",
   "metadata": {},
   "source": [
    "# 3. Plot the data\n",
    "We will now plot the discharge and the rainfall time series in the same graph, making sure that the discharge is referred to the primary y-axis, while rainfall refers to the secondary y-axis. Additionally, we want the secondary y-axis to be in inverse order and we want to draw the precipitation as bars. \n",
    "Below you find an example of the plot. You can look at this link https://matplotlib.org/stable/gallery/color/named_colors.html#sphx-glr-gallery-color-named-colors-py to check the named colors and change them yourself. Additional tutorials on how to plot figures are here https://matplotlib.org/stable/tutorials/index.html.\n",
    "At the end of the plot, there is a line to save the figure locally in your computer, in the folder where your notebook is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050c26d-134e-4420-b8b3-4ae9e13c4cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the figure\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "# Plot discharge on the primary y-axis\n",
    "ax1.plot(df['Date'], df['Qt'], color='steelblue', label='Discharge (m³/s)')\n",
    "ax1.set_xlabel('Time (hours)')\n",
    "ax1.set_ylabel('Discharge (m³/s)')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_ylim(0, 1000)  \n",
    "ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "ax1.xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=10))\n",
    "plt.xticks(rotation=45)\n",
    "ax1.set_xlim(df['Date'].loc[0], df['Date'].loc[len(df)-1])  # Set x-axis limits\n",
    "\n",
    "# Create secondary y-axis for rainfall\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(df['Date'], df['REt'], color='lightsteelblue',alpha=0.8, label='Rainfall (mm)')\n",
    "ax2.set_ylabel('Rainfall (mm)')\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.set_ylim(0, 20)  # \n",
    "ax2.invert_yaxis()  # Invert the secondary y-axis\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.title('Hourly Discharge and Rainfall')\n",
    "plt.show()\n",
    "plot_path = os.path.join(base_path, 'Rainfall-Discharge_Plot.png')\n",
    "# save the plot on your local folder\n",
    "plt.savefig(plot_path, dpi=600, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6772ff0-8af9-4f9d-878a-ee978236c9d0",
   "metadata": {},
   "source": [
    "# 4. Cross-correlation analysis\n",
    "We will now analyse the correlation between our target (Qt+1) and past rainfall (REt). More specifically, we want to analyse the correlation with past rainfall up to 9 steps in the past (REt-9). We can do it automatically in a loop, using the pandas library.\n",
    "This step is important because it gives a starting information on how many steps in the past (commonly referred as \"input features\") we should use to train our data driven models (we will see this part in the next notebooks). In case correlation is high, we have a good reason to believe that that specific variable is important to predict our target. In case correlation is low, it might be less relevant. Be careful, however, to remind that correlation measures the linear relationship between two variables. It might then happen that two variables are highly linked but not in a linear manner, and hence their linear correlation results low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb166e-768c-47b2-93ba-0d25d837fb43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute correlation between discharge and past rainfall steps\n",
    "correlations = {} # define empty dictionary where we store the correlation results\n",
    "for lag in range(1, 10):  # 10 steps back\n",
    "    df[f'REt_lag{lag}'] = df['REt'].shift(lag)\n",
    "    correlations[f'{lag}'] = df[['Qt', f'REt_lag{lag}']].corr().iloc[0, 1]\n",
    "\n",
    "# Print correlation results\n",
    "for lag, corr in correlations.items():\n",
    "    print(f'Correlation with {lag}: {corr:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3c3f2-6402-4638-bab7-ae7c5950a886",
   "metadata": {},
   "source": [
    "We can now plot the correlation coefficient across the different lags (time steps back in time). Also in this case, the plot is automatically saved in the folder where you have your jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5bc99-092e-449e-b36d-befd4a65f7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot correlation over different lags\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(list(correlations.keys()), list(correlations.values()), marker='o', linestyle='-', color='lightseagreen')\n",
    "ax.set_xlabel('Lag (hours)')\n",
    "ax.set_ylabel('Correlation coefficient')\n",
    "ax.set_ylim(-1,1)\n",
    "ax.set_title('Correlation between Discharge and Lagged Rainfall')\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "correlation_plot_path = os.path.join(base_path, 'Rainfall-Discharge_Correlation.png')\n",
    "plt.savefig(correlation_plot_path, dpi=600, format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1061df-dcfb-416c-88f2-66e6846134ab",
   "metadata": {},
   "source": [
    "<b>How many of the past rainfall time steps should we take to build our data driven model? </b>\n",
    "We can see that we have high correlation up to 6 hours back, so we could take all the first 6 lags of rainfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc6068-3e96-41e7-8ab0-893055f11122",
   "metadata": {},
   "source": [
    "# 5. Autocorrelation analysis\n",
    "Apart from past rainfall, also past discharge data might hold relevant information that could help our data driven model simulate better our target (Qt+1). We then analyse the autocorrelation of the discharge, which is the correlation between our target (Qt+1) and past discharge time steps (Qt). We analyse the autocorrelation up to 14 steps in the past (Qt-9). Please note that you can analyse as many time steps as you want. Practically, we use the same loop as before to compute the autocorrelation and we then plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec257e-03ed-47af-af74-5337af895ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qcorrelations = {} # define empty dictionary where we store the autocorrelation results\n",
    "for lag in range(1, 15):  # 14 steps back\n",
    "    df[f'Qt_lag{lag}'] = df['Qt'].shift(lag)\n",
    "    qcorrelations[f'{lag}'] = df[['Qt', f'Qt_lag{lag}']].corr().iloc[0, 1]\n",
    "\n",
    "# Print correlation results\n",
    "for lag, corr in qcorrelations.items():\n",
    "    print(f'Correlation with {lag}: {corr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787d88f-f41d-4660-91db-c098347a15bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot correlation over different lags\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(list(qcorrelations.keys()), list(qcorrelations.values()), marker='o', linestyle='-', color='goldenrod')\n",
    "ax.set_xlabel('Lag (hours)')\n",
    "ax.set_ylabel('Correlation coefficient')\n",
    "ax.set_ylim(-1,1)\n",
    "ax.set_xlim(0,13)\n",
    "ax.set_title('Discharge Autocorrelation')\n",
    "ax.grid(True)\n",
    "plt.show() \n",
    "autocorr_plot_path = os.path.join(base_path, 'Discharge_Autocorrelation.png')\n",
    "plt.savefig(autocorr_plot_path, dpi=600, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d6b61-60a6-4315-9ed2-16d6da341ef4",
   "metadata": {},
   "source": [
    "<b>How many of the past discharge time steps should we take to build our data driven model? </b>\n",
    "We can see that we have high correlation up to 6 hours back, so in principle we could take all the first 6 lags of discharge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b3461-627f-4075-84d4-4ab12466bac5",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "We have learnt how to plot our data and how to define, at least as first guess, which variables can be considered as input features for a data driven model.\n",
    "You can explore further and plot the data on scatter plots, with Qt+1 on the x-axis and one input variable on the y-axis. If they are aligned, there is a close linear relationship between the two. You can also extend the correlation analysis for more time lags.\n",
    "We will use this information in the next notebook, to build our first data driven model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
